{
    "results_output_path": "./result/results-llama-2-7b-chat-hf-arc_challenge.json",
    "steps": [
        {
            "step_type": "simple_multiple_choice",
            "step_name": "simple_multiple_choice-llama-2-7b-chat-hf-arc_challenge",
            "save_dataset": true,
            "dataset_config": {
                "type": "arc_challenge",
                "dataset_kwargs": {
                    "seed": 2,
                    "split": "test",
                    "name_or_path": "allenai/ai2_arc",
                    "config_name": "ARC-Challenge",
                    "fewshot_split": "train",
                    "fewshot_num": 5
                },
                "augment_dataset_kwargs": {
                    "num_instances": 4,
                    "num_keeps": 1
                }
            },
            "inference_config": {
                "type": "remote_hf",
                "output_path": "./result",
                "inference_kwargs": {
                    "model_name": "llama-2-7b-chat-hf",
                    "base_url": [
                        "http://your-tgi-url:port"
                    ],
                    "timeout": 60,
                    "num_workers": 4,
                    "request_limit": 100000,
                    "request_limit_period": 60,
                    "dump_individual_rsp": true,
                    "generation_config": {
                        "stop_sequences": [
                            "A",
                            "B",
                            "C",
                            "D",
                            "E"
                        ],
                        "max_new_tokens": 20
                    }
                }
            },
            "eval_config": {
                "aggregate_mode": "ignore_augmented"
            }
        },
        {
            "step_type": "interactive_evaluation",
            "step_name": "interactive_evaluation-llama-2-7b-chat-hf-arc_challenge",
            "output_path": "./result",
            "max_rounds": 5,
            "max_instances": 200,
            "prompter_config": {
                "mcp_prompt": "default",
                "interactor": {
                    "system_prompt": "default",
                    "init_user_prompt": "default"
                },
                "candidate": {
                    "system_prompt": "default"
                },
                "evaluator": {
                    "system_prompt": "clear",
                    "user_prompt": "add_detailed_criteria",
                    "init_user_prompt": "add_detailed_criteria",
                    "fewshot_prompt": "clear",
                    "system_prompt_json_example": "clear"
                }
            },
            "roles_config": {
                "candidate": {
                    "type": "remote_hf",
                    "inference_kwargs": {
                        "model_name": "llama-2-7b-chat-hf",
                        "base_url": [
                            "http://your-tgi-url:port"
                        ],
                        "timeout": 60,
                        "num_workers": 4,
                        "request_limit": 100000,
                        "request_limit_period": 60,
                        "dump_individual_rsp": true,
                        "generation_config": {
                            "max_new_tokens": 400
                        }
                    },
                    "prompt_postprocessor_config": {
                        "tokenizer_name_or_path": "meta-llama/Llama-2-7b-chat-hf",
                        "remove_system_prompt": false,
                        "add_generation_prompt": false
                    }
                },
                "interactor": {
                    "type": "openai",
                    "inference_kwargs": {
                        "openai_model": "gpt-4-1106-preview",
                        "openai_key": "your_openai_key",
                        "openai_api_base": "https://api.openai.com/v1/",
                        "openai_timeout": 120.0,
                        "generation_config": {
                            "max_tokens": 400,
                            "n": 1,
                            "temperature": 0.0,
                            "seed": 0
                        },
                        "num_workers": 16,
                        "request_limit": 100000,
                        "request_limit_period": 60,
                        "dump_individual_rsp": true
                    }
                },
                "evaluator": {
                    "type": "openai",
                    "inference_kwargs": {
                        "openai_model": "gpt-4-1106-preview",
                        "openai_key": "your_openai_key",
                        "openai_api_base": "https://api.openai.com/v1/",
                        "openai_timeout": 120.0,
                        "generation_config": {
                            "max_tokens": 400,
                            "n": 1,
                            "temperature": 0.0,
                            "seed": 0
                        },
                        "num_workers": 16,
                        "request_limit": 100000,
                        "request_limit_period": 60,
                        "dump_individual_rsp": true
                    }
                }
            }
        }
    ]
}